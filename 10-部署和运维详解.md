# 部署和运维详解 - 生产环境部署实践

## 问题背景

在博客项目开发完成后，需要将应用部署到生产环境。部署和运维是确保系统稳定运行的重要环节，包括容器化部署、负载均衡、监控告警、日志管理等。

## 部署和运维的核心问题

### 1. 部署问题
- 环境一致性
- 自动化部署
- 版本管理
- 回滚机制

### 2. 运维问题
- 系统监控
- 性能优化
- 故障处理
- 安全防护

### 3. 扩展问题
- 负载均衡
- 水平扩展
- 数据库集群
- 缓存集群

## Docker 容器化部署

### 1. 后端 Dockerfile

```dockerfile
# server/Dockerfile
FROM golang:1.23-alpine AS builder

# 设置工作目录
WORKDIR /app

# 安装依赖
RUN apk add --no-cache git ca-certificates tzdata

# 复制 go mod 文件
COPY go.mod go.sum ./

# 下载依赖
RUN go mod download

# 复制源代码
COPY . .

# 构建应用
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o main .

# 生产镜像
FROM alpine:latest

# 安装 ca-certificates 和 tzdata
RUN apk --no-cache add ca-certificates tzdata

# 设置时区
ENV TZ=Asia/Shanghai

# 创建非 root 用户
RUN addgroup -g 1001 -S appgroup && \
    adduser -u 1001 -S appuser -G appgroup

# 设置工作目录
WORKDIR /app

# 从构建阶段复制二进制文件
COPY --from=builder /app/main .
COPY --from=builder /app/config.yaml .
COPY --from=builder /app/uploads ./uploads

# 创建必要的目录
RUN mkdir -p /app/logs /app/uploads && \
    chown -R appuser:appgroup /app

# 切换到非 root 用户
USER appuser

# 暴露端口
EXPOSE 8080

# 健康检查
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD wget --no-verbose --tries=1 --spider http://localhost:8080/health || exit 1

# 启动应用
CMD ["./main"]
```

### 2. 前端 Dockerfile

```dockerfile
# web/Dockerfile
FROM node:18-alpine AS builder

# 设置工作目录
WORKDIR /app

# 复制 package 文件
COPY package*.json ./

# 安装依赖
RUN npm ci --only=production

# 复制源代码
COPY . .

# 构建应用
RUN npm run build

# 生产镜像
FROM nginx:alpine

# 复制构建产物
COPY --from=builder /app/dist /usr/share/nginx/html

# 复制 nginx 配置
COPY nginx.conf /etc/nginx/nginx.conf

# 创建非 root 用户
RUN addgroup -g 1001 -S appgroup && \
    adduser -u 1001 -S appuser -G appgroup

# 设置权限
RUN chown -R appuser:appgroup /usr/share/nginx/html && \
    chown -R appuser:appgroup /var/cache/nginx && \
    chown -R appuser:appgroup /var/log/nginx && \
    chown -R appuser:appgroup /etc/nginx/conf.d

# 切换到非 root 用户
USER appuser

# 暴露端口
EXPOSE 80

# 健康检查
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD wget --no-verbose --tries=1 --spider http://localhost/ || exit 1

# 启动 nginx
CMD ["nginx", "-g", "daemon off;"]
```

### 3. Docker Compose 配置

```yaml
# docker-compose.yml
version: '3.8'

services:
  # MySQL 数据库
  mysql:
    image: mysql:8.0
    container_name: blog_mysql
    restart: unless-stopped
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
    volumes:
      - mysql_data:/var/lib/mysql
      - ./mysql/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "3306:3306"
    networks:
      - blog_network
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      timeout: 20s
      retries: 10

  # Redis 缓存
  redis:
    image: redis:7-alpine
    container_name: blog_redis
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - blog_network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      timeout: 3s
      retries: 5

  # Elasticsearch 搜索引擎
  elasticsearch:
    image: elasticsearch:8.15.0
    container_name: blog_elasticsearch
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    volumes:
      - es_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - blog_network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Kibana 监控
  kibana:
    image: kibana:8.15.0
    container_name: blog_kibana
    restart: unless-stopped
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - blog_network

  # 后端应用
  backend:
    build:
      context: ./server
      dockerfile: Dockerfile
    container_name: blog_backend
    restart: unless-stopped
    environment:
      - GIN_MODE=release
      - MYSQL_HOST=mysql
      - MYSQL_PORT=3306
      - MYSQL_DATABASE=${MYSQL_DATABASE}
      - MYSQL_USER=${MYSQL_USER}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - ELASTICSEARCH_URL=http://elasticsearch:9200
    volumes:
      - ./server/uploads:/app/uploads
      - ./server/logs:/app/logs
    ports:
      - "8080:8080"
    depends_on:
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    networks:
      - blog_network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # 前端应用
  frontend:
    build:
      context: ./web
      dockerfile: Dockerfile
    container_name: blog_frontend
    restart: unless-stopped
    ports:
      - "80:80"
    depends_on:
      - backend
    networks:
      - blog_network
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost/"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Nginx 反向代理
  nginx:
    image: nginx:alpine
    container_name: blog_nginx
    restart: unless-stopped
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
      - ./nginx/logs:/var/log/nginx
    ports:
      - "443:443"
      - "80:80"
    depends_on:
      - frontend
      - backend
    networks:
      - blog_network

  # Prometheus 监控
  prometheus:
    image: prom/prometheus:latest
    container_name: blog_prometheus
    restart: unless-stopped
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - blog_network

  # Grafana 可视化
  grafana:
    image: grafana/grafana:latest
    container_name: blog_grafana
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      - grafana_data:/var/lib/grafana
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
    networks:
      - blog_network

volumes:
  mysql_data:
  redis_data:
  es_data:
  prometheus_data:
  grafana_data:

networks:
  blog_network:
    driver: bridge
```

## Nginx 配置

### 1. 主配置文件

```nginx
# nginx/nginx.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # 日志格式
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;

    # 基础配置
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 20M;

    # Gzip 压缩
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;

    # 上游服务器
    upstream backend {
        server backend:8080;
        keepalive 32;
    }

    upstream frontend {
        server frontend:80;
        keepalive 32;
    }

    # HTTP 重定向到 HTTPS
    server {
        listen 80;
        server_name yourdomain.com www.yourdomain.com;
        return 301 https://$server_name$request_uri;
    }

    # HTTPS 主服务器
    server {
        listen 443 ssl http2;
        server_name yourdomain.com www.yourdomain.com;

        # SSL 配置
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384;
        ssl_prefer_server_ciphers off;
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;

        # 安全头
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
        add_header X-Frame-Options DENY always;
        add_header X-Content-Type-Options nosniff always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header Referrer-Policy "strict-origin-when-cross-origin" always;

        # 前端静态文件
        location / {
            proxy_pass http://frontend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # 缓存静态资源
            location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg)$ {
                expires 1y;
                add_header Cache-Control "public, immutable";
            }
        }

        # API 接口
        location /api/ {
            proxy_pass http://backend/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # 超时配置
            proxy_connect_timeout 30s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;
        }

        # 文件上传
        location /uploads/ {
            proxy_pass http://backend/uploads/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # 文件上传大小限制
            client_max_body_size 20M;
        }

        # 健康检查
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }
    }
}
```

### 2. 前端 Nginx 配置

```nginx
# web/nginx.conf
events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # 日志格式
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;
    error_log /var/log/nginx/error.log warn;

    # 基础配置
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;

    # Gzip 压缩
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;

    server {
        listen 80;
        server_name localhost;
        root /usr/share/nginx/html;
        index index.html;

        # 安全头
        add_header X-Frame-Options DENY always;
        add_header X-Content-Type-Options nosniff always;
        add_header X-XSS-Protection "1; mode=block" always;

        # 静态资源缓存
        location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg)$ {
            expires 1y;
            add_header Cache-Control "public, immutable";
        }

        # HTML 文件不缓存
        location ~* \.html$ {
            expires -1;
            add_header Cache-Control "no-cache, no-store, must-revalidate";
        }

        # SPA 路由支持
        location / {
            try_files $uri $uri/ /index.html;
        }

        # 健康检查
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }
    }
}
```

## 监控和告警

### 1. 监控指标收集

```go
// server/middleware/metrics.go
package middleware

import (
    "strconv"
    "time"
    
    "github.com/gin-gonic/gin"
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promhttp"
)

var (
    // HTTP 请求计数器
    httpRequestsTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "http_requests_total",
            Help: "Total number of HTTP requests",
        },
        []string{"method", "endpoint", "status"},
    )

    // HTTP 请求持续时间
    httpRequestDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "http_request_duration_seconds",
            Help:    "HTTP request duration in seconds",
            Buckets: prometheus.DefBuckets,
        },
        []string{"method", "endpoint"},
    )

    // 活跃连接数
    httpRequestsInFlight = prometheus.NewGauge(
        prometheus.GaugeOpts{
            Name: "http_requests_in_flight",
            Help: "Current number of HTTP requests being processed",
        },
    )
)

func init() {
    prometheus.MustRegister(httpRequestsTotal)
    prometheus.MustRegister(httpRequestDuration)
    prometheus.MustRegister(httpRequestsInFlight)
}

// 监控中间件
func MetricsMiddleware() gin.HandlerFunc {
    return gin.HandlerFunc(func(c *gin.Context) {
        start := time.Now()
        
        // 增加活跃连接数
        httpRequestsInFlight.Inc()
        defer httpRequestsInFlight.Dec()
        
        // 处理请求
        c.Next()
        
        // 记录请求持续时间
        duration := time.Since(start).Seconds()
        httpRequestDuration.WithLabelValues(c.Request.Method, c.FullPath()).Observe(duration)
        
        // 记录请求计数
        status := strconv.Itoa(c.Writer.Status())
        httpRequestsTotal.WithLabelValues(c.Request.Method, c.FullPath(), status).Inc()
    })
}

// 暴露监控指标
func MetricsHandler() gin.HandlerFunc {
    return gin.WrapH(promhttp.Handler())
}
```

### 2. 性能监控中间件

```go
// server/middleware/performance.go
package middleware

import (
    "time"
    
    "github.com/gin-gonic/gin"
    "server/global"
)

// 性能监控中间件
func PerformanceMonitor() gin.HandlerFunc {
    return gin.HandlerFunc(func(c *gin.Context) {
        start := time.Now()
        
        // 处理请求
        c.Next()
        
        // 计算耗时
        duration := time.Since(start)
        
        // 记录性能指标
        global.LOG.Infof("请求耗时: %s %s %v", c.Request.Method, c.Request.URL.Path, duration)
        
        // 如果耗时超过阈值，记录警告
        if duration > 1*time.Second {
            global.LOG.Warnf("慢请求: %s %s %v", c.Request.Method, c.Request.URL.Path, duration)
        }
        
        // 记录到监控系统
        recordMetrics(c, duration)
    })
}

// 记录性能指标
func recordMetrics(c *gin.Context, duration time.Duration) {
    // 这里可以集成 Prometheus、StatsD 等监控系统
    metrics := map[string]interface{}{
        "method":     c.Request.Method,
        "path":       c.Request.URL.Path,
        "status":     c.Writer.Status(),
        "duration":   duration.Milliseconds(),
        "timestamp":  time.Now().Unix(),
    }
    
    // 发送到监控系统
    global.LOG.Infof("性能指标: %+v", metrics)
}
```

## 日志管理

### 1. 日志配置

```go
// server/initialize/zap.go
package initialize

import (
    "os"
    "path/filepath"
    
    "go.uber.org/zap"
    "go.uber.org/zap/zapcore"
    "server/global"
)

func InitZap() {
    // 创建日志目录
    logDir := "logs"
    if err := os.MkdirAll(logDir, 0755); err != nil {
        panic(err)
    }

    // 配置日志级别
    level := zap.NewAtomicLevel()
    if global.CONFIG.System.Env == "production" {
        level.SetLevel(zapcore.InfoLevel)
    } else {
        level.SetLevel(zapcore.DebugLevel)
    }

    // 配置编码器
    encoderConfig := zap.NewProductionEncoderConfig()
    encoderConfig.TimeKey = "timestamp"
    encoderConfig.EncodeTime = zapcore.ISO8601TimeEncoder
    encoderConfig.EncodeLevel = zapcore.CapitalLevelEncoder

    // 创建核心
    core := zapcore.NewCore(
        zapcore.NewJSONEncoder(encoderConfig),
        zapcore.AddSync(os.Stdout),
        level,
    )

    // 创建日志文件
    logFile, err := os.OpenFile(
        filepath.Join(logDir, "app.log"),
        os.O_APPEND|os.O_CREATE|os.O_WRONLY,
        0644,
    )
    if err != nil {
        panic(err)
    }

    // 文件核心
    fileCore := zapcore.NewCore(
        zapcore.NewJSONEncoder(encoderConfig),
        zapcore.AddSync(logFile),
        level,
    )

    // 合并核心
    combinedCore := zapcore.NewTee(core, fileCore)

    // 创建 logger
    logger := zap.New(combinedCore, zap.AddCaller(), zap.AddStacktrace(zapcore.ErrorLevel))
    
    global.LOG = logger.Sugar()
}
```

### 2. 日志轮转脚本

```bash
#!/bin/bash
# scripts/logrotate.sh

# 日志轮转脚本
LOG_DIR="/app/logs"
MAX_SIZE="100M"
MAX_FILES=10

# 轮转应用日志
logrotate_app() {
    local log_file="$LOG_DIR/app.log"
    local timestamp=$(date +%Y%m%d_%H%M%S)
    
    if [ -f "$log_file" ]; then
        local size=$(stat -c%s "$log_file")
        local max_size_bytes=$(numfmt --from=iec $MAX_SIZE)
        
        if [ $size -gt $max_size_bytes ]; then
            # 移动旧日志文件
            mv "$log_file" "$log_file.$timestamp"
            
            # 压缩旧日志文件
            gzip "$log_file.$timestamp"
            
            # 删除过多的日志文件
            ls -t "$LOG_DIR"/app.log.*.gz 2>/dev/null | tail -n +$((MAX_FILES + 1)) | xargs -r rm
            
            # 重新创建日志文件
            touch "$log_file"
        fi
    fi
}

# 轮转访问日志
logrotate_access() {
    local log_file="$LOG_DIR/access.log"
    local timestamp=$(date +%Y%m%d_%H%M%S)
    
    if [ -f "$log_file" ]; then
        local size=$(stat -c%s "$log_file")
        local max_size_bytes=$(numfmt --from=iec $MAX_SIZE)
        
        if [ $size -gt $max_size_bytes ]; then
            mv "$log_file" "$log_file.$timestamp"
            gzip "$log_file.$timestamp"
            ls -t "$LOG_DIR"/access.log.*.gz 2>/dev/null | tail -n +$((MAX_FILES + 1)) | xargs -r rm
            touch "$log_file"
        fi
    fi
}

# 主函数
main() {
    logrotate_app
    logrotate_access
}

main "$@"
```

## 自动化部署

### 1. 部署脚本

```bash
#!/bin/bash
# scripts/deploy.sh

set -e

# 配置
PROJECT_DIR="/opt/blog"
BACKUP_DIR="/opt/backups"
DOCKER_COMPOSE_FILE="$PROJECT_DIR/docker-compose.yml"

# 颜色输出
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

# 日志函数
log_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# 备份数据库
backup_database() {
    log_info "开始备份数据库..."
    
    timestamp=$(date +%Y%m%d_%H%M%S)
    backup_file="$BACKUP_DIR/mysql_backup_$timestamp.sql"
    
    mkdir -p "$BACKUP_DIR"
    
    docker-compose -f "$DOCKER_COMPOSE_FILE" exec -T mysql mysqldump \
        -u root -p"$MYSQL_ROOT_PASSWORD" \
        --all-databases > "$backup_file"
    
    log_info "数据库备份完成: $backup_file"
}

# 健康检查
health_check() {
    log_info "开始健康检查..."
    
    # 检查后端服务
    if curl -f http://localhost:8080/health > /dev/null 2>&1; then
        log_info "后端服务健康检查通过"
    else
        log_error "后端服务健康检查失败"
        return 1
    fi
    
    # 检查前端服务
    if curl -f http://localhost/ > /dev/null 2>&1; then
        log_info "前端服务健康检查通过"
    else
        log_error "前端服务健康检查失败"
        return 1
    fi
    
    log_info "所有服务健康检查通过"
}

# 回滚部署
rollback() {
    log_warn "开始回滚部署..."
    
    # 停止当前服务
    docker-compose -f "$DOCKER_COMPOSE_FILE" down
    
    # 恢复数据库备份
    if [ -f "$BACKUP_DIR/latest_backup.sql" ]; then
        log_info "恢复数据库备份..."
        docker-compose -f "$DOCKER_COMPOSE_FILE" exec -T mysql mysql \
            -u root -p"$MYSQL_ROOT_PASSWORD" < "$BACKUP_DIR/latest_backup.sql"
    fi
    
    # 启动服务
    docker-compose -f "$DOCKER_COMPOSE_FILE" up -d
    
    log_info "回滚完成"
}

# 主部署函数
deploy() {
    log_info "开始部署..."
    
    # 进入项目目录
    cd "$PROJECT_DIR"
    
    # 备份数据库
    backup_database
    
    # 拉取最新镜像
    log_info "拉取最新镜像..."
    docker-compose -f "$DOCKER_COMPOSE_FILE" pull
    
    # 停止服务
    log_info "停止当前服务..."
    docker-compose -f "$DOCKER_COMPOSE_FILE" down
    
    # 启动服务
    log_info "启动新服务..."
    docker-compose -f "$DOCKER_COMPOSE_FILE" up -d
    
    # 等待服务启动
    log_info "等待服务启动..."
    sleep 30
    
    # 健康检查
    if health_check; then
        log_info "部署成功"
        # 清理旧镜像
        docker system prune -f
    else
        log_error "部署失败，开始回滚"
        rollback
        exit 1
    fi
}

# 脚本入口
case "$1" in
    "deploy")
        deploy
        ;;
    "rollback")
        rollback
        ;;
    "health")
        health_check
        ;;
    "backup")
        backup_database
        ;;
    *)
        echo "用法: $0 {deploy|rollback|health|backup}"
        exit 1
        ;;
esac
```

## 安全配置

### 1. SSL 证书配置

```bash
#!/bin/bash
# scripts/ssl_setup.sh

# SSL 证书配置脚本
DOMAIN="yourdomain.com"
EMAIL="admin@yourdomain.com"

# 安装 Certbot
install_certbot() {
    if command -v certbot &> /dev/null; then
        echo "Certbot 已安装"
        return
    fi
    
    # Ubuntu/Debian
    if command -v apt-get &> /dev/null; then
        sudo apt-get update
        sudo apt-get install -y certbot python3-certbot-nginx
    # CentOS/RHEL
    elif command -v yum &> /dev/null; then
        sudo yum install -y certbot python3-certbot-nginx
    else
        echo "不支持的操作系统"
        exit 1
    fi
}

# 获取 SSL 证书
get_certificate() {
    echo "获取 SSL 证书..."
    sudo certbot --nginx -d $DOMAIN -d www.$DOMAIN --email $EMAIL --agree-tos --non-interactive
}

# 设置自动续期
setup_renewal() {
    echo "设置自动续期..."
    
    # 创建续期脚本
    cat > /etc/cron.d/certbot-renew << EOF
# 每天凌晨 2 点检查证书续期
0 2 * * * root /usr/bin/certbot renew --quiet --deploy-hook "systemctl reload nginx"
EOF
    
    # 测试续期
    sudo certbot renew --dry-run
}

# 主函数
main() {
    install_certbot
    get_certificate
    setup_renewal
    echo "SSL 证书配置完成"
}

main "$@"
```

### 2. 安全加固脚本

```bash
#!/bin/bash
# scripts/security_hardening.sh

# 系统安全加固脚本

# 更新系统
update_system() {
    echo "更新系统包..."
    if command -v apt-get &> /dev/null; then
        sudo apt-get update && sudo apt-get upgrade -y
    elif command -v yum &> /dev/null; then
        sudo yum update -y
    fi
}

# 配置防火墙
setup_firewall() {
    echo "配置防火墙..."
    
    # 安装 UFW (Ubuntu)
    if command -v apt-get &> /dev/null; then
        sudo apt-get install -y ufw
        sudo ufw default deny incoming
        sudo ufw default allow outgoing
        sudo ufw allow ssh
        sudo ufw allow 80/tcp
        sudo ufw allow 443/tcp
        sudo ufw --force enable
    # 配置 firewalld (CentOS)
    elif command -v yum &> /dev/null; then
        sudo systemctl enable firewalld
        sudo systemctl start firewalld
        sudo firewall-cmd --permanent --add-service=ssh
        sudo firewall-cmd --permanent --add-service=http
        sudo firewall-cmd --permanent --add-service=https
        sudo firewall-cmd --reload
    fi
}

# 配置 SSH 安全
secure_ssh() {
    echo "配置 SSH 安全..."
    
    # 备份 SSH 配置
    sudo cp /etc/ssh/sshd_config /etc/ssh/sshd_config.backup
    
    # 修改 SSH 配置
    sudo sed -i 's/#PermitRootLogin yes/PermitRootLogin no/' /etc/ssh/sshd_config
    sudo sed -i 's/#PasswordAuthentication yes/PasswordAuthentication no/' /etc/ssh/sshd_config
    sudo sed -i 's/#Port 22/Port 2222/' /etc/ssh/sshd_config
    
    # 重启 SSH 服务
    sudo systemctl restart sshd
}

# 安装安全工具
install_security_tools() {
    echo "安装安全工具..."
    
    if command -v apt-get &> /dev/null; then
        sudo apt-get install -y fail2ban rkhunter
    elif command -v yum &> /dev/null; then
        sudo yum install -y fail2ban rkhunter
    fi
    
    # 配置 fail2ban
    sudo systemctl enable fail2ban
    sudo systemctl start fail2ban
}

# 主函数
main() {
    update_system
    setup_firewall
    secure_ssh
    install_security_tools
    echo "系统安全加固完成"
}

main "$@"
```

## 性能优化

### 1. 系统性能调优

```bash
#!/bin/bash
# scripts/performance_tuning.sh

# 系统性能调优脚本

# 内核参数调优
tune_kernel() {
    echo "调优内核参数..."
    
    cat >> /etc/sysctl.conf << EOF
# 网络调优
net.core.somaxconn = 65535
net.core.netdev_max_backlog = 5000
net.ipv4.tcp_max_syn_backlog = 65535
net.ipv4.tcp_fin_timeout = 30
net.ipv4.tcp_keepalive_time = 1200
net.ipv4.tcp_max_tw_buckets = 5000
net.ipv4.tcp_tw_reuse = 1

# 文件系统调优
fs.file-max = 1000000
fs.inotify.max_user_watches = 524288

# 内存调优
vm.swappiness = 10
vm.dirty_ratio = 15
vm.dirty_background_ratio = 5
EOF
    
    # 应用配置
    sysctl -p
}

# 限制调优
tune_limits() {
    echo "调优系统限制..."
    
    cat >> /etc/security/limits.conf << EOF
# 用户限制
* soft nofile 1000000
* hard nofile 1000000
* soft nproc 65535
* hard nproc 65535

# root 用户限制
root soft nofile 1000000
root hard nofile 1000000
root soft nproc 65535
root hard nproc 65535
EOF
}

# Docker 调优
tune_docker() {
    echo "调优 Docker..."
    
    # 创建 Docker daemon 配置
    sudo mkdir -p /etc/docker
    cat > /etc/docker/daemon.json << EOF
{
  "storage-driver": "overlay2",
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m",
    "max-file": "3"
  },
  "default-ulimits": {
    "nofile": {
      "Name": "nofile",
      "Hard": 1000000,
      "Soft": 1000000
    }
  }
}
EOF
    
    # 重启 Docker
    sudo systemctl restart docker
}

# 主函数
main() {
    tune_kernel
    tune_limits
    tune_docker
    echo "系统性能调优完成"
}

main "$@"
```

## 总结

部署和运维是确保系统稳定运行的重要环节，需要综合考虑自动化、监控、日志管理、安全配置等多个方面。

**关键要点：**
- 容器化部署
- 负载均衡配置
- 监控告警系统
- 日志管理
- 自动化部署
- 安全加固
- 性能优化

**最佳实践：**
1. **容器化**: 使用 Docker 确保环境一致性
2. **自动化**: 建立完整的 CI/CD 流程
3. **监控**: 建立完善的监控和告警体系
4. **备份**: 定期备份重要数据
5. **安全**: 配置 SSL 证书和安全头
6. **性能**: 系统级和应用级性能优化
7. **文档**: 维护完整的部署和运维文档

**部署检查清单：**
- [ ] Docker 镜像构建和推送
- [ ] 环境变量配置
- [ ] 数据库迁移和初始化
- [ ] SSL 证书配置
- [ ] 防火墙和安全配置
- [ ] 监控和日志配置
- [ ] 备份策略实施
- [ ] 性能测试和调优
- [ ] 文档更新

通过合理的部署和运维配置，可以确保博客系统在生产环境中稳定运行，为用户提供良好的服务体验。

---

*本文详细介绍了部署和运维的各个方面，包括 Docker 部署、Nginx 配置、监控告警、安全配置等，希望对您的开发工作有所帮助。*
