# 性能优化详解 - 全面提升系统性能

## 问题背景

在博客项目中，随着用户量和数据量的增长，系统性能逐渐成为瓶颈。需要从多个层面进行性能优化，包括前端渲染、后端处理、数据库查询、缓存策略等。

## 性能优化的核心问题

### 1. 前端性能问题
- 页面加载速度
- 组件渲染性能
- 资源加载优化
- 用户体验优化

### 2. 后端性能问题
- API 响应时间
- 并发处理能力
- 内存使用优化
- 数据库查询优化

### 3. 系统架构问题
- 缓存策略设计
- 负载均衡配置
- 数据库连接池
- 监控和告警

## 前端性能优化

### 1. 代码分割和懒加载

```typescript
// router/index.ts
import { createRouter, createWebHistory } from 'vue-router'

const routes = [
  {
    path: '/',
    name: 'Home',
    component: () => import('@/views/Home.vue'), // 懒加载
  },
  {
    path: '/articles',
    name: 'Articles',
    component: () => import('@/views/Articles.vue'),
  },
  {
    path: '/article/:id',
    name: 'ArticleDetail',
    component: () => import('@/views/ArticleDetail.vue'),
  },
  {
    path: '/write',
    name: 'Write',
    component: () => import('@/views/Write.vue'),
    meta: { requiresAuth: true },
  },
]

const router = createRouter({
  history: createWebHistory(),
  routes,
})

export default router
```

### 2. 组件优化

```vue
<!-- components/OptimizedList.vue -->
<template>
  <div class="optimized-list">
    <div
      v-for="item in visibleItems"
      :key="item.id"
      class="list-item"
    >
      <ArticleCard :article="item" />
    </div>
    
    <!-- 虚拟滚动占位 -->
    <div v-if="total > visibleItems.length" class="virtual-scroll-placeholder" :style="{ height: placeholderHeight + 'px' }" />
    
    <!-- 加载更多 -->
    <div v-if="hasMore" class="load-more">
      <el-button @click="loadMore" :loading="loading">
        加载更多
      </el-button>
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, computed, onMounted, onUnmounted } from 'vue'
import { useIntersectionObserver } from '@vueuse/core'
import ArticleCard from './ArticleCard.vue'
import type { Article } from '@/types/article'

interface Props {
  articles: Article[]
  loading?: boolean
  hasMore?: boolean
}

const props = withDefaults(defineProps<Props>(), {
  loading: false,
  hasMore: false,
})

const emit = defineEmits<{
  loadMore: []
}>()

// 虚拟滚动相关
const containerRef = ref<HTMLElement>()
const itemHeight = 200 // 每个项目的高度
const visibleCount = 10 // 可见项目数量

// 计算可见项目
const visibleItems = computed(() => {
  return props.articles.slice(0, visibleCount)
})

// 计算占位高度
const placeholderHeight = computed(() => {
  return Math.max(0, (props.articles.length - visibleCount) * itemHeight)
})

// 加载更多
const loadMore = () => {
  if (!props.loading && props.hasMore) {
    emit('loadMore')
  }
}

// 使用 Intersection Observer 实现无限滚动
const { stop } = useIntersectionObserver(
  containerRef,
  ([{ isIntersecting }]) => {
    if (isIntersecting && props.hasMore && !props.loading) {
      loadMore()
    }
  },
  { threshold: 0.1 }
)

onUnmounted(() => {
  stop()
})
</script>

<style scoped>
.optimized-list {
  position: relative;
}

.list-item {
  margin-bottom: 20px;
}

.virtual-scroll-placeholder {
  width: 100%;
}

.load-more {
  text-align: center;
  margin-top: 20px;
}
</style>
```

### 3. 图片懒加载

```vue
<!-- components/LazyImage.vue -->
<template>
  <div class="lazy-image" ref="imageRef">
    <img
      v-if="isLoaded"
      :src="src"
      :alt="alt"
      :class="imageClass"
      @load="handleLoad"
      @error="handleError"
    />
    <div v-else class="image-placeholder" :class="placeholderClass">
      <el-skeleton-item variant="image" style="width: 100%; height: 100%" />
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, onMounted, onUnmounted } from 'vue'
import { useIntersectionObserver } from '@vueuse/core'

interface Props {
  src: string
  alt?: string
  width?: string | number
  height?: string | number
  lazy?: boolean
}

const props = withDefaults(defineProps<Props>(), {
  alt: '',
  lazy: true,
})

const imageRef = ref<HTMLElement>()
const isLoaded = ref(false)
const isInView = ref(false)

// 图片加载处理
const handleLoad = () => {
  isLoaded.value = true
}

const handleError = () => {
  // 处理图片加载失败
  console.error('图片加载失败:', props.src)
}

// 懒加载逻辑
const { stop } = useIntersectionObserver(
  imageRef,
  ([{ isIntersecting }]) => {
    if (isIntersecting) {
      isInView.value = true
      if (props.lazy) {
        // 延迟加载图片
        setTimeout(() => {
          isLoaded.value = true
        }, 100)
      }
    }
  },
  { threshold: 0.1 }
)

onMounted(() => {
  if (!props.lazy) {
    isLoaded.value = true
  }
})

onUnmounted(() => {
  stop()
})

// 样式计算
const imageClass = computed(() => ({
  'lazy-image__img': true,
  'lazy-image__img--loaded': isLoaded.value,
}))

const placeholderClass = computed(() => ({
  'lazy-image__placeholder': true,
  'lazy-image__placeholder--loading': !isLoaded.value,
}))
</script>

<style scoped>
.lazy-image {
  position: relative;
  overflow: hidden;
}

.lazy-image__img {
  width: 100%;
  height: 100%;
  object-fit: cover;
  transition: opacity 0.3s ease;
  opacity: 0;
}

.lazy-image__img--loaded {
  opacity: 1;
}

.lazy-image__placeholder {
  width: 100%;
  height: 100%;
  background: #f5f5f5;
  display: flex;
  align-items: center;
  justify-content: center;
}
</style>
```

### 4. 状态管理优化

```typescript
// stores/optimizedArticle.ts
import { defineStore } from 'pinia'
import { ref, computed } from 'vue'
import { getArticles } from '@/api/article'
import type { Article, ArticleFilters } from '@/types/article'

export const useOptimizedArticleStore = defineStore('optimizedArticle', () => {
  // 使用 Map 提高查找性能
  const articlesMap = ref(new Map<number, Article>())
  const filters = ref<ArticleFilters>({
    page: 1,
    pageSize: 20,
    category: '',
    tags: [],
    keyword: '',
  })
  
  const loading = ref(false)
  const hasMore = ref(true)
  const total = ref(0)

  // 计算属性优化
  const articles = computed(() => Array.from(articlesMap.value.values()))
  
  const articlesByCategory = computed(() => {
    const grouped = new Map<string, Article[]>()
    articles.value.forEach(article => {
      const category = article.category
      if (!grouped.has(category)) {
        grouped.set(category, [])
      }
      grouped.get(category)!.push(article)
    })
    return grouped
  })

  // 获取文章（带缓存）
  const getArticle = (id: number) => {
    return articlesMap.value.get(id)
  }

  // 批量获取文章
  const fetchArticles = async (newFilters?: Partial<ArticleFilters>) => {
    if (newFilters) {
      filters.value = { ...filters.value, ...newFilters, page: 1 }
      articlesMap.value.clear()
    }

    if (!hasMore.value || loading.value) return

    loading.value = true
    try {
      const response = await getArticles(filters.value)
      
      // 批量更新 Map
      response.data.forEach(article => {
        articlesMap.value.set(article.id, article)
      })
      
      total.value = response.total
      hasMore.value = articlesMap.value.size < response.total
      
      if (filters.value.page === 1) {
        filters.value.page = 1
      } else {
        filters.value.page++
      }
    } catch (error) {
      console.error('获取文章失败:', error)
    } finally {
      loading.value = false
    }
  }

  // 预加载文章
  const preloadArticle = async (id: number) => {
    if (articlesMap.value.has(id)) return
    
    try {
      const article = await getArticle(id)
      if (article) {
        articlesMap.value.set(id, article)
      }
    } catch (error) {
      console.error('预加载文章失败:', error)
    }
  }

  // 清理缓存
  const clearCache = () => {
    articlesMap.value.clear()
    filters.value.page = 1
    hasMore.value = true
    total.value = 0
  }

  return {
    articles,
    articlesByCategory,
    loading,
    hasMore,
    total,
    filters,
    getArticle,
    fetchArticles,
    preloadArticle,
    clearCache,
  }
})
```

## 后端性能优化

### 1. 数据库查询优化

```go
// service/optimized_article.go
package service

import (
    "context"
    "time"
    
    "server/global"
    "server/model/database"
    "server/model/response"
)

type OptimizedArticleService struct{}

// 优化后的文章列表查询
func (s *OptimizedArticleService) GetArticlesOptimized(filters map[string]interface{}, page, pageSize int) (*response.ArticleListResponse, error) {
    var articles []database.Article
    var total int64
    
    // 使用 context 控制超时
    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
    defer cancel()
    
    // 构建查询
    query := global.DB.WithContext(ctx).Model(&database.Article{})
    
    // 添加过滤条件
    if category, ok := filters["category"].(string); ok && category != "" {
        query = query.Joins("JOIN categories ON articles.category_id = categories.id").
            Where("categories.name = ?", category)
    }
    
    if keyword, ok := filters["keyword"].(string); ok && keyword != "" {
        query = query.Where("articles.title LIKE ? OR articles.content LIKE ?", 
            "%"+keyword+"%", "%"+keyword+"%")
    }
    
    if status, ok := filters["status"].(string); ok && status != "" {
        query = query.Where("articles.status = ?", status)
    }
    
    // 获取总数（使用缓存）
    cacheKey := fmt.Sprintf("article_count:%v", filters)
    if cached, err := global.REDIS.Get(ctx, cacheKey).Result(); err == nil {
        if count, err := strconv.ParseInt(cached, 10, 64); err == nil {
            total = count
        }
    } else {
        query.Count(&total)
        // 缓存总数 5 分钟
        global.REDIS.Set(ctx, cacheKey, total, 5*time.Minute)
    }
    
    // 分页查询
    offset := (page - 1) * pageSize
    err := query.Preload("User", "id,username,avatar").
        Preload("Category", "id,name").
        Preload("Tags", "id,name").
        Select("articles.id,articles.title,articles.summary,articles.cover_image,articles.view_count,articles.like_count,articles.comment_count,articles.created_at,articles.updated_at").
        Order("articles.created_at DESC").
        Offset(offset).
        Limit(pageSize).
        Find(&articles).Error
    
    if err != nil {
        return nil, err
    }
    
    return &response.ArticleListResponse{
        Articles: articles,
        Total:    total,
        Page:     page,
        PageSize: pageSize,
    }, nil
}

// 批量获取文章详情
func (s *OptimizedArticleService) GetArticlesBatch(ids []uint) ([]database.Article, error) {
    if len(ids) == 0 {
        return []database.Article{}, nil
    }
    
    var articles []database.Article
    
    // 使用 IN 查询批量获取
    err := global.DB.Preload("User", "id,username,avatar").
        Preload("Category", "id,name").
        Preload("Tags", "id,name").
        Where("id IN ?", ids).
        Find(&articles).Error
    
    return articles, err
}

// 文章搜索优化
func (s *OptimizedArticleService) SearchArticlesOptimized(keyword string, page, pageSize int) (*response.ArticleListResponse, error) {
    var articles []database.Article
    var total int64
    
    // 使用全文索引搜索
    query := global.DB.Where("MATCH(title, content) AGAINST(? IN BOOLEAN MODE)", keyword)
    
    // 获取总数
    query.Model(&database.Article{}).Count(&total)
    
    // 分页查询
    offset := (page - 1) * pageSize
    err := query.Preload("User", "id,username,avatar").
        Preload("Category", "id,name").
        Select("id,title,summary,cover_image,view_count,like_count,comment_count,created_at,updated_at").
        Order("MATCH(title, content) AGAINST(?) DESC", keyword).
        Offset(offset).
        Limit(pageSize).
        Find(&articles).Error
    
    if err != nil {
        return nil, err
    }
    
    return &response.ArticleListResponse{
        Articles: articles,
        Total:    total,
        Page:     page,
        PageSize: pageSize,
    }, nil
}
```

### 2. 缓存策略

```go
// service/cache_service.go
package service

import (
    "context"
    "encoding/json"
    "fmt"
    "time"
    
    "server/global"
)

type CacheService struct{}

// 缓存配置
type CacheConfig struct {
    Key        string
    TTL        time.Duration
    Serializer func(interface{}) ([]byte, error)
    Deserializer func([]byte, interface{}) error
}

// 获取缓存
func (s *CacheService) Get(ctx context.Context, key string, dest interface{}) error {
    data, err := global.REDIS.Get(ctx, key).Result()
    if err != nil {
        return err
    }
    
    return json.Unmarshal([]byte(data), dest)
}

// 设置缓存
func (s *CacheService) Set(ctx context.Context, key string, value interface{}, ttl time.Duration) error {
    data, err := json.Marshal(value)
    if err != nil {
        return err
    }
    
    return global.REDIS.Set(ctx, key, data, ttl).Err()
}

// 删除缓存
func (s *CacheService) Delete(ctx context.Context, keys ...string) error {
    return global.REDIS.Del(ctx, keys...).Err()
}

// 批量获取缓存
func (s *CacheService) MGet(ctx context.Context, keys []string) (map[string]interface{}, error) {
    result := make(map[string]interface{})
    
    for _, key := range keys {
        var value interface{}
        if err := s.Get(ctx, key, &value); err == nil {
            result[key] = value
        }
    }
    
    return result, nil
}

// 批量设置缓存
func (s *CacheService) MSet(ctx context.Context, data map[string]interface{}, ttl time.Duration) error {
    pipe := global.REDIS.Pipeline()
    
    for key, value := range data {
        dataBytes, err := json.Marshal(value)
        if err != nil {
            continue
        }
        pipe.Set(ctx, key, dataBytes, ttl)
    }
    
    _, err := pipe.Exec(ctx)
    return err
}

// 缓存装饰器
func (s *CacheService) WithCache(config CacheConfig) func(func() (interface{}, error)) func() (interface{}, error) {
    return func(fn func() (interface{}, error)) func() (interface{}, error) {
        return func() (interface{}, error) {
            ctx := context.Background()
            
            // 尝试从缓存获取
            var result interface{}
            if err := s.Get(ctx, config.Key, &result); err == nil {
                return result, nil
            }
            
            // 执行原函数
            data, err := fn()
            if err != nil {
                return nil, err
            }
            
            // 设置缓存
            if config.TTL > 0 {
                s.Set(ctx, config.Key, data, config.TTL)
            }
            
            return data, nil
        }
    }
}

// 文章缓存服务
type ArticleCacheService struct {
    cache *CacheService
}

func NewArticleCacheService() *ArticleCacheService {
    return &ArticleCacheService{
        cache: &CacheService{},
    }
}

// 获取文章缓存
func (s *ArticleCacheService) GetArticle(id uint) (*database.Article, error) {
    key := fmt.Sprintf("article:%d", id)
    
    var article database.Article
    err := s.cache.Get(context.Background(), key, &article)
    return &article, err
}

// 设置文章缓存
func (s *ArticleCacheService) SetArticle(article *database.Article) error {
    key := fmt.Sprintf("article:%d", article.ID)
    return s.cache.Set(context.Background(), key, article, 30*time.Minute)
}

// 删除文章缓存
func (s *ArticleCacheService) DeleteArticle(id uint) error {
    key := fmt.Sprintf("article:%d", id)
    return s.cache.Delete(context.Background(), key)
}

// 获取文章列表缓存
func (s *ArticleCacheService) GetArticleList(filters map[string]interface{}, page, pageSize int) (*response.ArticleListResponse, error) {
    key := fmt.Sprintf("article_list:%v:%d:%d", filters, page, pageSize)
    
    var result response.ArticleListResponse
    err := s.cache.Get(context.Background(), key, &result)
    return &result, err
}

// 设置文章列表缓存
func (s *ArticleCacheService) SetArticleList(filters map[string]interface{}, page, pageSize int, data *response.ArticleListResponse) error {
    key := fmt.Sprintf("article_list:%v:%d:%d", filters, page, pageSize)
    return s.cache.Set(context.Background(), key, data, 10*time.Minute)
}

// 清除文章相关缓存
func (s *ArticleCacheService) ClearArticleCache() error {
    ctx := context.Background()
    pattern := "article:*"
    
    keys, err := global.REDIS.Keys(ctx, pattern).Result()
    if err != nil {
        return err
    }
    
    if len(keys) > 0 {
        return s.cache.Delete(ctx, keys...)
    }
    
    return nil
}
```

### 3. 并发处理优化

```go
// service/concurrent_service.go
package service

import (
    "context"
    "sync"
    "time"
    
    "server/global"
)

type ConcurrentService struct{}

// 并发获取文章详情
func (s *ConcurrentService) GetArticlesWithDetails(ids []uint) ([]database.Article, error) {
    if len(ids) == 0 {
        return []database.Article{}, nil
    }
    
    // 限制并发数
    semaphore := make(chan struct{}, 10)
    var wg sync.WaitGroup
    
    articles := make([]database.Article, len(ids))
    errors := make([]error, len(ids))
    
    for i, id := range ids {
        wg.Add(1)
        go func(index int, articleID uint) {
            defer wg.Done()
            
            // 获取信号量
            semaphore <- struct{}{}
            defer func() { <-semaphore }()
            
            // 获取文章详情
            var article database.Article
            err := global.DB.Preload("User").
                Preload("Category").
                Preload("Tags").
                First(&article, articleID).Error
            
            articles[index] = article
            errors[index] = err
        }(i, id)
    }
    
    wg.Wait()
    
    // 检查错误
    for _, err := range errors {
        if err != nil {
            return nil, err
        }
    }
    
    return articles, nil
}

// 批量更新文章统计
func (s *ConcurrentService) BatchUpdateArticleStats(updates map[uint]map[string]interface{}) error {
    if len(updates) == 0 {
        return nil
    }
    
    // 使用事务批量更新
    return global.DB.Transaction(func(tx *gorm.DB) error {
        for articleID, stats := range updates {
            if err := tx.Model(&database.Article{}).
                Where("id = ?", articleID).
                Updates(stats).Error; err != nil {
                return err
            }
        }
        return nil
    })
}

// 异步处理任务
type AsyncTask struct {
    ID       string
    Type     string
    Data     interface{}
    Priority int
    CreatedAt time.Time
}

type AsyncProcessor struct {
    taskQueue chan AsyncTask
    workers   int
    stopChan  chan struct{}
}

func NewAsyncProcessor(workers int) *AsyncProcessor {
    processor := &AsyncProcessor{
        taskQueue: make(chan AsyncTask, 1000),
        workers:   workers,
        stopChan:  make(chan struct{}),
    }
    
    // 启动工作协程
    for i := 0; i < workers; i++ {
        go processor.worker()
    }
    
    return processor
}

func (p *AsyncProcessor) worker() {
    for {
        select {
        case task := <-p.taskQueue:
            p.processTask(task)
        case <-p.stopChan:
            return
        }
    }
}

func (p *AsyncProcessor) processTask(task AsyncTask) {
    switch task.Type {
    case "update_article_stats":
        p.processUpdateArticleStats(task)
    case "send_notification":
        p.processSendNotification(task)
    case "generate_thumbnail":
        p.processGenerateThumbnail(task)
    default:
        global.LOG.Warnf("未知任务类型: %s", task.Type)
    }
}

func (p *AsyncProcessor) processUpdateArticleStats(task AsyncTask) {
    // 处理文章统计更新
    if data, ok := task.Data.(map[string]interface{}); ok {
        articleID := data["article_id"].(uint)
        viewCount := data["view_count"].(int64)
        
        global.DB.Model(&database.Article{}).
            Where("id = ?", articleID).
            UpdateColumn("view_count", gorm.Expr("view_count + ?", viewCount))
    }
}

func (p *AsyncProcessor) processSendNotification(task AsyncTask) {
    // 处理发送通知
    global.LOG.Infof("发送通知: %+v", task.Data)
}

func (p *AsyncProcessor) processGenerateThumbnail(task AsyncTask) {
    // 处理生成缩略图
    global.LOG.Infof("生成缩略图: %+v", task.Data)
}

func (p *AsyncProcessor) AddTask(task AsyncTask) {
    select {
    case p.taskQueue <- task:
    default:
        global.LOG.Warn("任务队列已满")
    }
}

func (p *AsyncProcessor) Stop() {
    close(p.stopChan)
}
```

## 数据库优化

### 1. 索引优化

```sql
-- 文章表索引优化
CREATE INDEX idx_articles_status_created_at ON articles(status, created_at DESC);
CREATE INDEX idx_articles_category_created_at ON articles(category_id, created_at DESC);
CREATE INDEX idx_articles_user_created_at ON articles(user_id, created_at DESC);
CREATE INDEX idx_articles_title_content ON articles(title, content(100));

-- 评论表索引优化
CREATE INDEX idx_comments_article_status ON comments(article_id, status);
CREATE INDEX idx_comments_parent_path ON comments(parent_id, path);
CREATE INDEX idx_comments_created_at ON comments(created_at DESC);

-- 用户表索引优化
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_username ON users(username);
CREATE INDEX idx_users_created_at ON users(created_at DESC);

-- 标签关联表索引优化
CREATE INDEX idx_article_tags_article ON article_tags(article_id);
CREATE INDEX idx_article_tags_tag ON article_tags(tag_id);
```

### 2. 查询优化

```go
// service/query_optimizer.go
package service

import (
    "server/global"
    "server/model/database"
)

type QueryOptimizer struct{}

// 优化文章列表查询
func (o *QueryOptimizer) GetArticlesOptimized(filters map[string]interface{}, page, pageSize int) ([]database.Article, error) {
    var articles []database.Article
    
    query := global.DB.Model(&database.Article{})
    
    // 使用索引优化查询
    if status, ok := filters["status"].(string); ok && status != "" {
        query = query.Where("status = ?", status)
    }
    
    if categoryID, ok := filters["category_id"].(uint); ok && categoryID > 0 {
        query = query.Where("category_id = ?", categoryID)
    }
    
    if userID, ok := filters["user_id"].(uint); ok && userID > 0 {
        query = query.Where("user_id = ?", userID)
    }
    
    // 只选择需要的字段
    err := query.Select("id, title, summary, cover_image, view_count, like_count, comment_count, created_at").
        Preload("User", "id, username, avatar").
        Preload("Category", "id, name").
        Order("created_at DESC").
        Offset((page - 1) * pageSize).
        Limit(pageSize).
        Find(&articles).Error
    
    return articles, err
}

// 优化文章详情查询
func (o *QueryOptimizer) GetArticleWithDetails(id uint) (*database.Article, error) {
    var article database.Article
    
    err := global.DB.Preload("User", "id, username, avatar, bio").
        Preload("Category", "id, name, description").
        Preload("Tags", "id, name").
        Preload("Comments", "status = ?", "approved").
        First(&article, id).Error
    
    return &article, err
}

// 批量查询优化
func (o *QueryOptimizer) GetArticlesBatch(ids []uint) ([]database.Article, error) {
    if len(ids) == 0 {
        return []database.Article{}, nil
    }
    
    var articles []database.Article
    
    err := global.DB.Where("id IN ?", ids).
        Preload("User", "id, username, avatar").
        Preload("Category", "id, name").
        Find(&articles).Error
    
    return articles, err
}

// 统计查询优化
func (o *QueryOptimizer) GetArticleStats() (map[string]interface{}, error) {
    var stats struct {
        TotalArticles   int64 `json:"total_articles"`
        PublishedArticles int64 `json:"published_articles"`
        TotalViews      int64 `json:"total_views"`
        TotalLikes      int64 `json:"total_likes"`
        TotalComments   int64 `json:"total_comments"`
    }
    
    // 使用单次查询获取所有统计
    err := global.DB.Raw(`
        SELECT 
            COUNT(*) as total_articles,
            SUM(CASE WHEN status = 'published' THEN 1 ELSE 0 END) as published_articles,
            SUM(view_count) as total_views,
            SUM(like_count) as total_likes,
            SUM(comment_count) as total_comments
        FROM articles
    `).Scan(&stats).Error
    
    if err != nil {
        return nil, err
    }
    
    return map[string]interface{}{
        "total_articles":     stats.TotalArticles,
        "published_articles": stats.PublishedArticles,
        "total_views":        stats.TotalViews,
        "total_likes":        stats.TotalLikes,
        "total_comments":     stats.TotalComments,
    }, nil
}
```

## 监控和性能分析

### 1. 性能监控

```go
// middleware/performance.go
package middleware

import (
    "time"
    
    "github.com/gin-gonic/gin"
    "server/global"
)

// 性能监控中间件
func PerformanceMonitor() gin.HandlerFunc {
    return gin.HandlerFunc(func(c *gin.Context) {
        start := time.Now()
        
        // 处理请求
        c.Next()
        
        // 计算耗时
        duration := time.Since(start)
        
        // 记录性能指标
        global.LOG.Infof("请求耗时: %s %s %v", c.Request.Method, c.Request.URL.Path, duration)
        
        // 如果耗时超过阈值，记录警告
        if duration > 1*time.Second {
            global.LOG.Warnf("慢请求: %s %s %v", c.Request.Method, c.Request.URL.Path, duration)
        }
        
        // 记录到监控系统
        recordMetrics(c, duration)
    })
}

// 记录性能指标
func recordMetrics(c *gin.Context, duration time.Duration) {
    // 这里可以集成 Prometheus、StatsD 等监控系统
    metrics := map[string]interface{}{
        "method":     c.Request.Method,
        "path":       c.Request.URL.Path,
        "status":     c.Writer.Status(),
        "duration":   duration.Milliseconds(),
        "timestamp":  time.Now().Unix(),
    }
    
    // 发送到监控系统
    global.LOG.Infof("性能指标: %+v", metrics)
}
```

### 2. 性能分析工具

```go
// utils/profiler.go
package utils

import (
    "runtime"
    "runtime/pprof"
    "time"
)

type Profiler struct{}

// CPU 性能分析
func (p *Profiler) StartCPUProfile() (*os.File, error) {
    file, err := os.Create("cpu_profile.prof")
    if err != nil {
        return nil, err
    }
    
    pprof.StartCPUProfile(file)
    return file, nil
}

func (p *Profiler) StopCPUProfile() {
    pprof.StopCPUProfile()
}

// 内存性能分析
func (p *Profiler) WriteHeapProfile() error {
    file, err := os.Create("heap_profile.prof")
    if err != nil {
        return err
    }
    defer file.Close()
    
    return pprof.WriteHeapProfile(file)
}

// 获取内存统计
func (p *Profiler) GetMemoryStats() map[string]interface{} {
    var m runtime.MemStats
    runtime.ReadMemStats(&m)
    
    return map[string]interface{}{
        "alloc":      m.Alloc,
        "total_alloc": m.TotalAlloc,
        "sys":        m.Sys,
        "num_gc":     m.NumGC,
        "goroutines": runtime.NumGoroutine(),
    }
}

// 性能基准测试
func (p *Profiler) Benchmark(name string, fn func()) time.Duration {
    start := time.Now()
    fn()
    duration := time.Since(start)
    
    global.LOG.Infof("基准测试 %s: %v", name, duration)
    return duration
}
```

## 总结

性能优化是一个系统性的工程，需要从前端、后端、数据库等多个层面进行综合考虑。

**关键要点：**
- 前端渲染优化
- 后端并发处理
- 数据库查询优化
- 缓存策略设计
- 监控和告警

**最佳实践：**
1. **分层优化**: 从前端到数据库逐层优化
2. **缓存优先**: 合理使用缓存减少计算开销
3. **异步处理**: 使用异步处理提高响应速度
4. **监控告警**: 建立完善的监控体系
5. **持续优化**: 根据监控数据持续优化

通过系统性的性能优化，可以显著提升博客系统的用户体验和系统稳定性。

---

*本文详细介绍了性能优化的各个方面，包括前端优化、后端优化、数据库优化等，希望对您的开发工作有所帮助。*
